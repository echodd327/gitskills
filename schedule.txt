如何读源码？
1. 看测试代码，有助于了解源码
2. 了解相关知识。mybatis用到jar包  cglib.jar-->asm.jar
3. 画设计图,比如类图,uml活动图等
4. 了解各模块功能，看相关资料
5. 自己写测试代码调试源代码
6. 猜测类和方法的作用。

每次看源码都是走马光花
如何学设计模式?
1.了解各个设计模式概念和例子 
2.看成熟第三方框架, 理解
3.根据模拟现实场景训练
-------------------------------------------------------------------------------------------------------------------------
Tomcat集群搭建
分布式远程通讯:  rmi rpc jms activeMQ  kafka 
J2EE:  session/cookie get/post

-----------------------------------------------------------------------------------------------------------------------------------
mybatis 源码分析 ---> 
类加载器  jndi  OSGi
动态字节码 asm cglib javassist
1.parsing-->原生DOM、SAX、Xpath解析

设计模式-->工厂模式,建造者模式,单例模式,合成模式,装饰模式,代理模式，模板模式，迭代器模式，适配器模式
        -->针对现有代码,设计场景，做训练。

2.builder-->组合模式, 策略模式
3.plugin(拦截器)--> Annotation、jdk动态代理
3.annotaion-->
4.logging-->
5.io --> nio
6.executor-->
7.cache -->
8.exception -->


将步骤组合起来
--------------------------------------------------------------------------------------------------------------------------
hadoop (HDFS、MapReduce)

bio/nio/netty



分布式缓存   	redis memcached
分布式消息服务  JMS ActiveMQ kafka
分布式计算 		mapreduce storm
软负载均衡   
-----------------------------------------------------------------------------------------------------------------------
数据库连接池: jndi/c3p0/DBCP
-----------------------------------------------------------------------------------------------------------------------

oracle 数字 varchar  number?
-----------------------------------------------------------------------------------------------------------------
class文件结构各个组成部分,定义，数据结构和使用方法


字节码流如何在虚拟机执行引擎最终解释执行。

1. 类加载时机

2. 类加载过程

3. 类加载器
--------------------------------------------------------------------------------------------------------------------------------------
抢红包:
WechatPromoActyController类 accessWeiXinActivityPageNew

--------------------------------------------------------------------------------------------------------------------------------------

面向对象编程
面向过程编程

JAXP (Java API for XML Processing) 是java xml程序设计的应用程序接口之一。

名称空间上下文 
   若xml文档中元素在名称空间里,查询该文档的XPath

org.w3c.dom(java dom)解析xml文档

--------------------------------------------------------------------------------------------------------------------------------------
数据库连接池
poolMaximumActiveConnections = 10;  最大活跃连接数  
poolMaximumIdleConnections = 5;     最大空闲连接数
poolMaximumCheckoutTime = 20000;    被强制返回之前,池中连接被检查时间 20s
poolTimeToWait = 20000;             尝试连接时间


before:	1480650332229
after:	1480650332419
Create Costs:		190ms  获取连接要190毫秒   如果并发10000个客户都获取一次数据库连接要 = 31分钟， 所以说创建一个java.sql.connection对象代价是巨大的。再底层相当于与数据库底层建立通信连接,在建立通信连接时候消耗了那么多时间，可能只执行一个简单sql就抛弃掉.这是非常大的资源浪费。
Exec Costs:		73ms       执行一个SQL要73毫秒  

解决方案:
对频繁跟数据交互的应用程序，可以将connection对方放到内存中，下次直接再内存中取出来。

调用close方法的Connection对象所持有资源全部释放掉,Connection对象也不再使用。如何调用该方法,不释放资源,将Connection放回数据库连接池中。


hsqlDB 开放源代码的JAVA数据库,标准SQL语法和JAVA接口。具有Server模式,每个程序需要不同命令运行。 
支持ANSI-92 标准的 SQL 语法  org.hsqldb.jdbcDriver
--------------------------------------------------------------------------------------------------------------------------------------
缓存
1. 什么是一级缓存？
每次使用Mybatis与数据库回话,Mybatis都会创建一次sqlSession数据库会话,如果反复执行相同语句,极短时间内查询结果相同,由于查询一次数据库代价很大，会造成
很大资源浪费。

MyBatis会在一次会话的表示----一个SqlSession对象中创建一个本地缓存(local cache)，对于每一次查询，都会尝试根据查询的条件去本地缓存中查找是否在缓存中，如果在缓存中，就直接从缓存中取出，然后返回给用户；否则，从数据库读取数据，将查询结果存入缓存并返回给用户。

2.Mybatis一级缓存如何组织？
对于会话级别的一级缓存也应该是在SqlSession中控制的。
sqlSession使用Executor,Executor使用Cache

3.一级缓存生命周期多长?
a. MyBatis在开启一个数据库会话时，会 创建一个新的SqlSession对象，SqlSession对象中会有一个新的Executor对象，Executor对象中持有一个新的PerpetualCache对象；当会话结束时，SqlSession对象及其内部的Executor对象还有PerpetualCache对象也一并释放掉。
b. 如果SqlSession调用了close()方法，会释放掉一级缓存PerpetualCache对象，一级缓存将不可用；
c. 如果SqlSession调用了clearCache()，会清空PerpetualCache对象中的数据，但是该对象仍可使用；
d.SqlSession中执行了任何一个update操作(update()、delete()、insert()) ，都会清空PerpetualCache对象的数据，但是该对象可以继续使用；


4.Cache接口设计以及CacheKey定义。
Cache实际上是一个Map,
  1.如何判断两次查询是同一个查询 ？   statementId  + rowBounds  + 传递给JDBC的SQL  + 传递给JDBC的参数值
  2.如何确定key值。


LRU（Least recently used，最近最少使用）算法根据数据的历史访问记录来进行淘汰数据，其核心思想是“如果数据最近被访问过，那么将来被访问的几率也更高”。

HashMap 的基础构造器为HashMap(int initialCapacity,float loadFactor)带有两个参数,他们是初始容量initialCapacity和负载因子loadFactor。
        因为默认情况下，数组大小为 16，那么当 HashMap 中元素个数超过 16*0.75=12 的时候，就把数组的大小扩展为 2*16=32，即扩大一倍，然后重新计算每个元素在数组中的位置，而这是一个非常消耗性能的操作
		1.当负载因子越大，对空间的利用更充分，然后后果是查找效率的降低
		2.如果负载因子太小，那么散列表的数据将过于稀疏，对空间造成严重浪费

--------------------------------------------------------------------------------------------------
我们可以看到在 HashMap 中要找到某个元素，需要根据 key 的 hash 值来求得对应数组中的位置。如何计算这个位置就是 hash 算法。前面说过 HashMap 的数据结构是数组和链表的结合，所以我们当然希望这个 HashMap 里面的 元素位置尽量的分布均匀些，尽量使得每个位置上的元素数量只有一个，那么当我们用 hash 算法求得这个位置的时候，马上就可以知道对应位置的元素就是我们要的，而不用再去遍历链表，这样就大大优化了查询的效率。

--------------------------------------------------------------------------------------------------
NIO

为什么要使用selector?
1. 通过单线程处理多个channels
2. 因为对于操作系统来说,线程切换开销很大。线程也耗费系统资源(比如内存)
3. 因此线程使用越少越好。
4. 但是计算机cpu多任务处理越来越好,多线程开销减少了，不使用多任务浪费cpu能力。

Channel: FileChannel, DatagramChannel,SocketChannel,ServerSocketChannel
Buffer:  ByteBuffer,MappedByteBuffer,CharBuffer,DoubleBuffer,FloatBuffer,IntBuffer,LongBuffer,ShortBuffer

阻塞服务器
1.必须为每个数据数量都分配一个单独线程。原因就在于IO接口在读取数据时在有数据返回前会一直被阻塞住。无法用单线程来处理一个流
2.并发数不高比如每一时刻只有几百并发,也行不会有太大问题,但上升到百万级别。 
  每个线程需要为堆栈分配320KB（32位JVM）到1024KB(64位JVM)的内存空间 1,000,000个线程=1000000M=1TB内存空间
3.为了减少线程数，很多服务器都设计了线程池，把所有接收到的请求放到队列内，每次读取一条连接进行处理



--------------------------------------------------------------------------------------------------
JAVA TCP/UDP Socket编程
1.IP 网络层协议
2.TCP/UDP 传输层协议使用地址为端口号.
  socket 类型为流套接字（使用 TCP 协议）和数据报套接字（使用 UDP 协议,一次只能发送最长 65507 个字节）
3.TCP/IP,一个端对端协议（TCP 协议或 UDP 协议）以及一个端口号唯一确定
4.每个端口都标识了一台主机上的一个应用程序，实际上，一个端口确定了一个主机上的一个套接字,主机中的多个程序可以同时访问同一个套接字


UDP
1.在 IP 协议的基础上添加了端口；
2.对传输过程中可能产生的数据错误进行了检测，并抛弃已经损坏的数据。

TCP、UDP、HTTP 等在传输数据时，都是以位序列编码的(即二进制字节编码)
应用程序协议中明确定义了信息的发送者应该如何排列和解释这些位序列，同时还要定义接收者应该如何解析，这样才能使信息的接收者能够抽取出每个字段的意义
TCP/IP 协议唯一的约束：信息必须在块中发送和接收，而块的长度必须是 8 位的倍数，因此，我们可以认为 TCP/IP 协议中传输的信息是字节序列。


 UDP 套接字保留了消息的边界信息，因此不需要进行成帧处理	
 TCP 协议中没有消息边界 成帧就是一个非常重要的考虑因素 最后一个字节后，将受到一个流结束标记，即 read（）返回-1
 
 
----基于线程池的TCP-----
1、线程池服务器创建一个ServerSocket
2、创建N个线程,多个线程池调用ServerSocket的一个实例accept方法,都阻塞等待。
3、一个线程完成服务,继续等待连接，不终止。

线程池：如果创建线程太多,(空闲线程太多),会消耗很多系统资源;如果创建线程太少, 客户端需要等很长时间才能获得服务。
	    Executor接口,按照某种策略执行Runnable对象,包含排队或者调度等序列。


nio  tcp/udp网络编程 --->并发线程  --> Reactor  --> netty

(java NIO Socket) VS (java BIO Socket)

数据读写操作:
标准的 IO 是基于字节流和字符流进行操作的，它不能前后移动流中的数据，而 NIO 是基于通道（Channel）和缓冲区（Buffer）进行操作的，数据总是从通道读取到缓冲区中，或者从缓冲区写入到通道中，需要时可以在缓冲区中前后移动所保存的数据。


IO特点:
1. accept()等待客户端连接,read()方法,write()方法发生阻塞
2.线程被挂起，什么都干不了。
3.CPU切换

非阻塞特点:
1.把整个过程切换成小的任务，通过任务间协作完成。
2.由一个专门的线程来处理所有的 IO 事件，并负责分发。
3.事件驱动机制：事件到的时候触发，而不是同步的去监视事件。
4.线程通讯：线程之间通过 wait,notify 等方式通讯。保证每次上下文切换都是有意义的。减少无谓的进程切换。



----基于 NIO 的 TCP 通信-----
1.NIO采用通道(channel)和缓冲区(buffer)来传输和保存数据,在等待连接,读写数据时服务器还可以干别的事情
2.上千客户端连接服务器时,如果线程池或者-线程-客户端模式非常浪费资源。
3.一个selector  多个channel。


--------------------------------------------------------------------------------------------------
Java并发性和多线程

http://blog.jobbole.com/101134/  应用？

多线程优点
1.CPU能再系统等待磁盘IO/网络IO时候/用户输入时候,做一些其他事情，提高资源利用率
2.程序设计更加简单
3.程序响应更加快。

多线程缺点
1.设计更复杂
2.上下文切换的开销。
  当 CPU 从执行一个线程切换到执行另外一个线程的时候，它需要先存储当前线程的本地的数据，程序指针等，然后载入另一个线程的本地数据，程序指针等，最后才开始执行
3.增加资源消耗

分布式文件系统与并发编程模型类似。
1. 并行工作模式
2. 流水线并发模型 (Non blocking io)
3. 函数式并行（Functional Parallelism） 如java.util.concurrent包里面的 ForkAndJoinPool

竞态条件 & 临界区
在同一程序中运行多个线程本身不会导致问题，问题在于多个线程访问了相同的资源。如，同一内存区（变量，数组，或对象）、系统（数据库，web services 等）或文件。

线程安全:
1. 局部变量和局部对象。局部变量存储在线程自己栈中。局部对象存储共享堆中,但是其他线程获取不到该对象
2. 对象成员存储在堆上。如果两个线程同时更新同一个对象的同一个成员，那这个代码就不是线程安全的。


线程之间通信
1.通过共享对象通信。必须是同一个对象,否则不能通信
2.JAVA内建的等待机制来允许线程在等待信号的时候变为非运行状态.Java.lang.Object 类定义了三个方法，wait()、notify()和 notifyAll()来实现这个等待机制。
  a、A线程调用wait,变成非运行状态,知道B线程调用同一个对象notify()方法。 
  b、两个线程必须获得同一个锁。

等待线程在同步块里面执行的时候，不是一直持有监视器对象（myMonitor 对象）的锁吗？等待线程不能阻塞唤醒线程进入 doNotify()的同步块吗？
答案是：的确不能。一旦线程调用了 wait()方法，它就释放了所持有的监视器对象上的锁。这将允许其他线程也可以调用 wait()或者 notify()。

一旦notify()先执行，在wait()前空唤醒，则另外一个线程则永远等待下去。

多个线程等待相同信号。notifyAll()

死锁: 两个或更多线程阻塞着等待其它处于死锁状态的线程所持有的锁。死锁通常发生在多个线程同时但以不同的顺序请求同一组锁的时候。
锁/公平锁

Slipped condition,就是说,从一个线程检查某个特定条件到该线程操作此条件期间，这个条件已被其他线程改变，导致第一个线程在该条件执行中错误操作。

读写锁为什么用notifyAll()?
答: 如果有线程在等待获取读锁，同时又有线程在等待获取写锁。如果这时其中一个等待读锁的线程被 notify 方法唤醒，但因为此时仍有请求写锁的线程存在（writeRequests>0），所以被唤醒的线程会再次进入阻塞状态。然而，等待写锁的线程一个也没被唤醒，就像什么也没发生过一样（译者注：信号丢失现象）。如果用的是 notifyAll 方法，所有的线程都会被唤醒，然后判断能否获得其请求的锁。


-----------------git--start--------------------------------------------------------------------------------------------------------------------------------------------
步骤一, 修改文件
步骤二, 查看修改内容  $ git diff readme.txt 
步骤三, 查看状态 $ git status 
步骤四, 添加文件 $ git add readme.txt
步骤五, 提交 $ git commit -m "add distributed"  (-m 后面添加提交描述)

查看历史版本 $ git log 
简洁查看历史版本 $ git log --pretty=oneline
bf3921d8ce0d824bdf0d2f58ee56502ef1078e0f append GPL
9d8ef65dd9821a7e2292dc1fc35ba8d444b1601d add distributed
874b98bb390a4639339e0dc9962a42756537213e wrote a readme file

返回上一个版本  $ git reset --hard HEAD^
回到未来版本    $ git reset --hard bf3921d8ce0d824bdf0d2f58ee56502ef1078e0f
回退到某个版本,又想回到新版本，忘记commit id,可以查看记录你每次命令 $ git reflog

为什么Git比其他版本控制器设计得优秀得多,因为Git跟踪并管理修改,而非文件。（修改文件->add文件-->修改文件-->提交文件) 实际只提交了第一版
撤销修改   $ git checkout -- readme.txt  有两种情况
  a.一种是,readme.txt自修改后还没有放到暂存区,现在撤销就回到版本一模一样的状态。
  b.一种是 readme.txt 已经添加到暂存区后，又作了修改，现在，撤销修改就回到添加到暂存区后的状态。 
      $ git reset HEAD readme.txt ，再回到a

删除文件 $ git rm test.txt ,如果没有提交 $ git checkout -- readme.txt  可以进行还原
删除文件提交 $ git commit -m "remove test.txt"  ,再$ git reset --hard HEAD^  进行还原

git远程仓库
1.生成SSH key
  $ ssh-keygen -t rsa -C "1219983404@qq.com"
  然后将ssh关联 GitHub
2.再GitHub添加远程库 create a new repo...
   $ git remote add origin git@github.com:echodd327/learngit.git
   再将内容推送 
   $ git push -u origin master ,将当前分支推送到远程
    
3.我们先有本地库,然后再从本地库关联远程库, 现在创建远程库,从远程库克隆  
  gitHub创建一个远程库,创建READ.md文件。
  克隆一个本地库: $ git clone git@github.com:echodd327/gitskills.git

4.Git 支持多种协议，包括 https，但通过 ssh 支持的原生 git 协议速度最快。

分支
分支在实际中有什么用呢？假设你准备开发一个新功能，但是需要两周才能完成，第一周你写了50%的代码，如果立刻提交，由于代码还没写完，不完整的代码库会导致别人不能干活了。如果等代码全部写完再一次提交，又存在丢失每天进度的巨大风险。
创建属于自己的分支,在自己的分支上干活，想提交就提交，直到开发完毕后，再一次性合并到原来的分支上
1.创建分支
   $ git checkout -b dev 相当于两条命令: $ git branch dev , $ git checkout dev
2.查看分支
   $ git branch
3. 把dev工作结果合并到master分支
   $ git merge dev
4. 删除分支
   $ git branch -d dev   
5. 分支合并冲突   $ git merge dev
    <<<<<<< HEAD
Creating a new branch is quick & simple.
=======
Creating a new branch is quick AND simple.

6. 查看分支合并情况
   $ git log --graph --pretty=oneline --abbrev-commit

7. 分支管理策略
   fast forward模式,删除分支会丢掉分支信息。
   合并后，我们用git log看看分支历史 $ git log --graph --pretty=oneline --abbrev-commit
8. bug分支
   dev 分支不想提交,要切换到master分支修改bug,在master分支新建一个分支issue-101
   a. 保存当前分支工作现场 $ git stash, 然后你可以放心创建分支修复bug
   b. 切换主分区,创建分支,修改Bug,合并，删除bug分支
       $ git checkout master
	   $ git checkout -b issue-101
	   $ git add readme.txt 
	   $ git checkout master
	   $ git merge --no-ff -m "merged bug fix 101" issue-101
	   $ git branch -d issue-101 
   c. 回到dev分支,查看刚才工作现场
       $ git stash list
		stash@{0}: WIP on dev: 6224937 add merge
   d. 恢复现场, 两种方式
       d.1. 一种是git stash apply恢复，再用git stash drop来删除
	   d.2. 一种是git stash pop,恢复的同时把 stash 内容也删了
	   
   e. 查看，也可以恢复指定stash 
	  $ git stash apply stash@{0}
9. feature分支
   添加新功能时,不希望实质性功能代码把分支搞乱,添加一个功能新建一个feature分支。完成后,合并，删除
   强行删除分支 $ git branch -D feature-vulcan

10.多人协作
    a. 推送dev分支。  $ git push origin dev
	b. 克隆到本地  $ git clone git@github.com:echodd327/gitskills.git ,默认情况下小伙伴只能看到master分支
	c. 将远程dev分支克隆到本地, $ git checkout -b dev origin/dev
	d. 修改,推送到远程库 $ git push origin dev
	

如果本地与远程别人提交有冲突,则提交后报错
xiu@xiu-pc-F66 MINGW64 ~/gitskills (dev)
$ git push origin dev
To github.com:echodd327/gitskills.git
 ! [rejected]        dev -> dev (fetch first)
error: failed to push some refs to 'git@github.com:echodd327/gitskills.git'
hint: Updates were rejected because the remote contains work that you do
hint: not have locally. This is usually caused by another repository pushing
hint: to the same ref. You may want to first integrate the remote changes
hint: (e.g., 'git pull ...') before pushing again.
hint: See the 'Note about fast-forwards' in 'git push --help' for details.

先用git pull把最新的提交从 origin/dev 抓下来，然后，在本地合并，解决冲突，再推送
xiu@xiu-pc-F66 MINGW64 ~/gitskills (dev)
$ git pull
remote: Counting objects: 2, done.
remote: Compressing objects: 100% (1/1), done.
remote: Total 2 (delta 0), reused 2 (delta 0), pack-reused 0
Unpacking objects: 100% (2/2), done.
From github.com:echodd327/gitskills
 * [new branch]      dev        -> origin/dev
There is no tracking information for the current branch.
Please specify which branch you want to merge with.
See git-pull(1) for details.

    git pull <remote> <branch>

If you wish to set tracking information for this branch you can do so with:

    git branch --set-upstream-to=origin/<branch> dev

git pull也失败了，原因是没有指定本地 dev 分支与远程 origin/dev 分支的链接，根据提示，设置 dev 和 origin/dev 的链接：

	


-------------------------------------------------------------------------------------------------------------------------------------------------------------


BoneCP 是一个高性能的开源java数据库连接池,他的设计初衷就是提高数据库连接池性能。只依赖slf4j和guava
Tomcat是一个Servlet容器，他首先需要做以下事情
1.实现servlet api规范,Servlet大部分是api接口规范，如request,response,session,cookie
2.启动socket监听端口,等待http请求。
3.获取http请求，分发请求给不同的协议处理器，如http和https在处理上是不一样的。
4.封装请求，构造HttpServletRequest。把socket获取的用户请求字节流转换成java对象httprequest。构造httpResponse。
5.调用(若未创建，则先加载)servlet，调用init初始化，执行servlet.service()方法。
6.为httpResponse添加header等头部信息。
7.socket回写流，返回满足http协议格式的数据给浏览器。
8.实现JSP语法分析器，JSP标记解释器。JSP servlet实现和渲染引擎。
9.JNDI、JMX等服务实现。容器一般额外提供命名空间服务管理。
10.线程池管理，创建线程池，并为每个请求分配线程。


JVM三种预定义类型类加载器
1. 启动（Bootstrap）类加载器 
   引导类装入器是用本地代码实现的类装入器,<Java_Runtime_Home>/lib 下面的类库加载到内存中
	
2. 标准扩展（Extension）类加载器
   扩展类加载器是由 Sun 的 ExtClassLoader（sun.misc.Launcher$ExtClassLoader） 实现的,< Java_Runtime_Home >/lib/ext 
   
3. 系统（System）类加载器
   Sun 的 AppClassLoader（sun.misc.Launcher$AppClassLoader）实现的

 
秒杀抢购思路以及高并发下数据安全   
WEB系统吞吐率: QPS(Query for second,每秒处理请求数)，以解决每秒数万次高并发场景
  理论峰值QPS为（理想化的计算方式）= 20*500/0.1 = 100000(10w)  20台Apache的web服务器, maxClient(Apache最大连接数)500个,每个业务平均响应100ms
  
 http://blog.jobbole.com/107224/
 
 心态: 定目标,激发内心欲望
 学习：
 
--------------------------------------------------------------------------------------------------
kafka 分布式消息系统

*************************************hadoop学习 start ***************************************************************
https://www.zhihu.com/question/29690410  

第一阶段: hadoop基本使用和实现原理
0. 相关知识了解: 比如分布式数据库,分布式网络通信调度， RPC,NIO,设计模式等。
1. hadoop shell对hdfs进行操作,hdfs api操作文件上传下载
2. MapReduce api数据处理问题
3. 了解内部原理,看博客,数据。《Hadoop权威指南》
4. HDFS基本架构以及各个模块功能、读写文件流程。 (Master/slave架构, nameNode DataNode,SecondNameNode)
5. MapReduce具体工作流程。如partition,shuffle,sort等
6. 多跟别人交流,讲给别人听。



第二阶段: 从无到入门，开始阅读hadoop源代码
1. 选择hadoop组件
   a.如果对分布式存储感兴趣,选择HDFS (√)
   b.如果对分布式计算感兴趣,选择MapReduce  (数据结构和算法)
   c.如果对资源管理感兴趣,选择YARN  (√)
   d.可以从测试案例开始看

2. hadoop都是master/slave模式。记住阅读的代码属于哪一个模块，会在哪个组件中执行
   如分布式RPC,是hadoop自己实现的

3. 阅读一些源代码分析博客和数据。比如《Hadoop技术内幕》系列丛书

4. 这个阶段目的是对hadoop整体架构和细节有所了解,比如MapReduce Scheduler是怎样实现的。Shffle过程。
   遇到问题可以迅速定位具体类和函数，通过阅读源码解决问题。
---------------------------------------------------------------------------------------------------   
HDP开发者认证  
   
http://ifeve.com/hortonworkshdp-hdpcd/
   
涉及的jar包
1、JAXB 能够使用Jackson对JAXB注解支持实现，既方便生成XML，也方便生成JSON，这样一来可以更好的标志可以转换为JSON对象的JAVA类。
2、avro 序列化
3、jetty servlet容器
4、netty  供异步的、事件驱动的网络应用程序框架和工具，用以快速开发高性能、高可靠性的网络服务器和客户端程序


*************************************hadoop学习 end ***************************************************************


























 